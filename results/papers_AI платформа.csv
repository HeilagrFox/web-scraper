Link,Title,Authors,Abstract
https://doi.org/10.31376/2410-0897-2024-1-54-31-40,USING CLASSTIME'S AI-BASED TESTING IN LEARNING OUTCOMES ASSESSMENT,Halyna Lutsenko; Oksana Podolian; Valerii Hrytsenko,"Досліджено проблему оцінювання навчальних досягнень здобувачів освіти цифровими засобами. Здійснено аналіз досліджень щодо використання штучного інтелекту в практиці освітньої діяльності. Обґрунтовано необхідність використання систем та засобів штучного інтелекту для вирішення освітніх завдань. Апробовано можливості штучного інтелекту платформи Classtime для оцінювання результатів навчання студентів інформатичних й інженерних спеціальностей. Виділено ключові функціональні складники, які забезпечують засоби штучного інтелекту в платформах оцінювання навчальних досягнень: автоматизація оцінювання, аналіз відповідей, індивідуалізація завдань. Ключові слова: оцінювання, штучний інтелект, платформа Classtime, майбутні вчителі інформатики, майбутні інженери."
https://arxiv.org/abs/2401.15897,Red-Teaming for Generative AI: Silver Bullet or Security Theater?,Michael Feffer; Anusha Sinha; Zachary Chase Lipton; Hoda Heidari,"In response to rising concerns surrounding the safety, security, and trustworthiness of Generative AI (GenAI) models, practitioners and regulators alike have pointed to AI red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite AI red-teaming’s central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the AI industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for AI red-teaming practices. Our analysis reveals that prior methods and practices of AI red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing GenAI harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard AI, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative AI, we synthesize our recommendations into a question bank meant to guide and scaffold future AI red-teaming practices."
https://doi.org/10.36622/1682-7813.2024.27.3.001,ЦИФРОВАЯ ПЛАТФОРМА ДЛЯ ЗАЩИЩЕННЫХ ИНФОРМАЦИОННО- УПРАВЛЯЮЩИХ СИСТЕМ БЕСПИЛОТНОГО ТРАНСПОРТА,Владимир Александрович Минаев; А.С. Толпыгин,"Цифровая трансформация транспортного комплекса России сопровождается активным внедрением новых технологий, созданием мультимодальных транспортных систем, применением беспилотных транспортных средств, управляемых искусственным интеллектом. Безопасность на транспорте неразрывно связана с кибербезопасностью систем управления. В статье рассматриваются решения, заложенные в ядро цифровой платформы, обеспечивающих защиту информации и киберустойчивость систем управления (СУ) беспилотных авиационных систем. Цифровая платформа беспилотных авиационных систем разрабатывается как инструмент и системотехническая основа для создания автоматизированных систем контроля и управления беспилотным транспортом, обеспечения их быстрого масштабирования за счет тиражирования унифицированных модулей. Подсистема защиты информации цифровой платформы создается в соответствии с требованиями регуляторов ФСТЭК России, Минобороны России и ФСБ России и в соответствии с требованиями к системе защиты информации, опирающейся на систему моделей угроз и нарушителей, рассмотренную в [1]. Особое внимание уделяется защите систем искусственного интеллекта, применяемым для управления беспилотными авиационными системами.
 The digital transformation of the Russian transport complex is accompanied by the active introduction of new technologies, the creation of multimodal transport systems, and the use of unmanned vehicles controlled by artificial intelligence (AI). Transport security is inextricably linked to the cybersecurity of control systems (CS). The article discusses the solutions embedded in the core of the digital platform that ensure information protection and cyber stability of CS of unmanned aircraft systems (UAS). The digital platform is being developed as a tool and a system-technical basis for creating automated control and management systems for unmanned vehicles, ensuring their rapid scaling through the replication of unified modules. The information protection subsystem of the digital platform is created in accordance with the requirements of the regulators of the FSTEC of Russia, the Ministry of Defense of Russia and the FSS of Russia and in accordance with the requirements for an information protection system based on a system of threat and intruder models discussed in [1]. Special attention is paid to the protection of artificial intelligence systems used to control UAS."
https://doi.org/10.1007/s43681-024-00419-4,Anthropomorphism in AI: hype and fallacy,Adriana Placani,"This essay focuses on anthropomorphism as both a form of hype and fallacy. As a form of hype, anthropomorphism is shown to exaggerate AI capabilities and performance by attributing human-like traits to systems that do not possess them. As a fallacy, anthropomorphism is shown to distort moral judgments about AI, such as those concerning its moral character and status, as well as judgments of responsibility and trust. By focusing on these two dimensions of anthropomorphism in AI, the essay highlights negative ethical consequences of the phenomenon in this field."
https://doi.org/10.32835/2707-3092.2024.29.189-199,ЦИФРОВА ПЛАТФОРМА ЯК ЗАСІБ ПРОФЕСІЙНОЇ ПІДГОТОВКИ ТА КОМУНІКАЦІЇ МАЙБУТНІХ КВАЛІФІКОВАНИХ РОБІТНИКІВ МАШИНОБУДІВНОЇ ГАЛУЗІ,Владислав Белан,"The relevance of this research is driven by new demands on the vocational education system, particularly in the mechanical engineering sector, amid the digital transformation of the economy and the emergence of Industry 4.0. Given the rapid pace of technological advancement, there is an urgent need to integrate digital educational platforms into the training of skilled workers. Digital platforms can provide access to modern educational resources, personalized learning pathways, and simulations of production processes. This enables vocational training to better align with the needs of a high-tech labor market, making it more flexible, interactive, and effective.
Objective: To develop and justify methodological principles for creating a digital educational platform for the vocational training of future skilled workers in the mechanical engineering industry, taking into account current trends in digitalization, industry-specific features, and learners’ educational needs.
Methods: Theoretical analysis of scientific sources on digital platforms, vocational education, and Industry 4.0 technologies; modeling of the functional structure of the educational platform with consideration of its goal-oriented, content-based, methodological, and communicative components; comparative analysis of existing digital platforms based on criteria such as functionality, user interaction, and adaptability to educational needs; expert evaluation of pedagogical and technical solutions for the platform; design and testing of a website that includes interactive learning modules on CAD, CNC, and robotics, as well as analytical tools for progress monitoring.
Results: The study summarizes the classification of digital platforms by functionality and user interaction; formulates methodological principles for the development of educational platforms in the mechanical engineering sector (personalization, accessibility, interactivity, compliance with industry standards); develops a prototype of a digital platform for training future specialists, including adaptive learning, video content, simulations, analytics dashboards, and integration with LMS and social networks; substantiates the feasibility of incorporating digital technologies such as AI, AR/VR, IoT, and blockchain into the platform structure; justifies the need to enhance teachers’ digital competence for the effective implementation of platform-based learning.
Conclusions: As a result of the conducted study, it was demonstrated that the digital platform is a key tool for modernizing the vocational education system in the context of digital transformation, particularly for the machine-building industry. It enables the integration of individualized learning with the real demands of the labor market, creating a flexible educational environment that fosters the development of professional competencies in future skilled workers of the machine-building sector. The developed methodological model of the platform, which includes target, content, methodological, and communicative components, ensures the integration of the educational process with modern production technologies and labor market requirements. The implementation of the digital platform concept requires an interdisciplinary approach, technical support, and regulatory legal framework; however, it holds significant potential for the modernization of vocational education. The effectiveness of the digital platform depends on its ability to integrate modern technologies, support educators, provide feedback, and meet professional training standards. "
https://doi.org/10.1007/s00146-024-01889-0,"Generative AI and human–robot interaction: implications and future agenda for business, society and ethics",Bojan Obrenovic; Xiaochuan Gu; Guoyu Wang; Danijela Godinic; Ilimdorjon J. Jakhongirov,
https://doi.org/10.1007/s43681-024-00443-4,AI hype as a cyber security risk: the moral responsibility of implementing generative AI in business,Declan Humphreys; Abigail Koay; Dennis Desmond; Erica Mealy,"This paper examines the ethical obligations companies have when implementing generative Artificial Intelligence (AI). We point to the potential cyber security risks companies are exposed to when rushing to adopt generative AI solutions or buying into “AI hype”. While the benefits of implementing generative AI solutions for business have been widely touted, the inherent risks associated have been less well publicised. There are growing concerns that the race to integrate generative AI is not being accompanied by adequate safety measures. The rush to buy into the hype of generative AI and not fall behind the competition is potentially exposing companies to broad and possibly catastrophic cyber-attacks or breaches. In this paper, we outline significant cyber security threats generative AI models pose, including potential ‘backdoors’ in AI models that could compromise user data or the risk of ‘poisoned’ AI models producing false results. In light of these the cyber security concerns, we discuss the moral obligations of implementing generative AI into business by considering the ethical principles of beneficence, non-maleficence, autonomy, justice, and explicability. We identify two examples of ethical concern, overreliance and over-trust in generative AI, both of which can negatively influence business decisions, leaving companies vulnerable to cyber security threats. This paper concludes by recommending a set of checklists for ethical implementation of generative AI in business environment to minimise cyber security risk based on the discussed moral responsibilities and ethical concern."
https://doi.org/10.1007/s43681-024-00427-4,Artificial intelligence (AI) cybersecurity dimensions: a comprehensive framework for understanding adversarial and offensive AI,Masike Malatji; Alaa Tolah,"As Artificial Intelligence (AI) rapidly advances and integrates into various domains, cybersecurity emerges as a critical field grappling with both the benefits and pitfalls of AI technologies. This paper explores the multifaceted dimensions of AI-driven cyberattacks, offering insights into their implications, mitigation strategies, underlying motivations, and profound societal impacts. The research centres on developing and presenting the AI Cybersecurity Dimensions (AICD) Framework, a comprehensive, multidimensional schema designed to guide academics, policymakers, and industry professionals in understanding and combating the evolving challenges posed by AI-driven cyber threats. The research unveils the complex dynamics of offensive AI, stressing the need for adaptive defences and ethical considerations. Concurrently, the study highlights adversarial AI threats, calling for proactive measures to address their potential ramifications. Through rigorous textual analyses and extensive literature reviews, the paper underscores the urgency for interdisciplinary approaches to bridge the technology-humanity chasm traditionally observed in cybersecurity discussions. By synthesising these diverse elements, the AICD Framework emerges as an instrumental tool for holistic understanding and practical interventions in the AI-infused cybersecurity landscape. The paper concludes with an urgent call for collaborative efforts in research and practice to navigate the intricate challenges and capitalise on the opportunities borne from the convergence of AI and cybersecurity."
https://doi.org/10.1609/aies.v7i1.31717,Gaps in the Safety Evaluation of Generative AI,Maribeth Rauh; Nahema Marchal; Arianna Manzini; L. Hendricks; R. Comanescu; Canfer Akbulut; Tom Stepleton; Juan Mateos-Garcia; Stevie Bergman; Jackie Kay; Conor Griffin; Ben Bariach; Iason Gabriel; Verena Rieser; William Isaac; Laura Weidinger,"Generative AI systems produce a range of ethical and social risks. Evaluation of these risks is a critical step on the path to ensuring the safety of these systems. However, evaluation requires the availability of validated and established measurement approaches and tools. In this paper, we provide an empirical review of the methods and tools that are available for evaluating known safety of generative AI systems to date. To this end, we review more than 200 safety-related evaluations that have been applied to generative AI systems. We categorise each evaluation along multiple axes to create a detailed snapshot of the safety evaluation landscape to date. We release this data for researchers and AI safety practitioners (https://bitly.ws/3hUzu). Analysing the current safety evaluation landscape reveals three systemic ”evaluation gaps”. First, a ”modality gap” emerges as few safety evaluations exist for non-text modalities. Second, a ”risk coverage gap” arises as evaluations for several ethical and social risks are simply lacking. Third, a ”context gap” arises as most safety evaluations are model-centric and fail to take into account the broader context in which AI systems operate. Devising next steps for safety practitioners based on these findings, we present tactical ”low-hanging fruit” steps towards closing the identified evaluation gaps and their limitations. We close by discussing the role and limitations of safety evaluation to ensure the safety of generative AI systems."
https://pmc.ncbi.nlm.nih.gov/articles/PMC11638409,Enhancing interpretability and accuracy of AI models in healthcare: a comprehensive review on challenges and future directions,Mohammad Ennab; Hamid Mcheick,"Artificial Intelligence (AI) has demonstrated exceptional performance in automating critical healthcare tasks, such as diagnostic imaging analysis and predictive modeling, often surpassing human capabilities. The integration of AI in healthcare promises substantial improvements in patient outcomes, including faster diagnosis and personalized treatment plans. However, AI models frequently lack interpretability, leading to significant challenges concerning their performance and generalizability across diverse patient populations. These opaque AI technologies raise serious patient safety concerns, as non-interpretable models can result in improper treatment decisions due to misinterpretations by healthcare providers. Our systematic review explores various AI applications in healthcare, focusing on the critical assessment of model interpretability and accuracy. We identify and elucidate the most significant limitations of current AI systems, such as the black-box nature of deep learning models and the variability in performance across different clinical settings. By addressing these challenges, our objective is to provide healthcare providers with well-informed strategies to develop innovative and safe AI solutions. This review aims to ensure that future AI implementations in healthcare not only enhance performance but also maintain transparency and patient safety."
https://habr.com/ru/companies/yougile/articles/957690/,"10 систем управления проектами с AI: проверила, где искусственный интеллект работает без менеджеров",Ekaterina_Severnaja,"AI давно обещает избавить менеджеров от рутины, но делает ли он это на самом деле?Я проверила 10 систем управления проектами — от таск-трекеров до больших платформ — и посмотрела, где искусственный интеллект работает лучше людей. Читать далее"
https://habr.com/ru/news/961810/,В «Яндекс Учебнике» появился «Репетитор AI» и новый предмет — математика,Lexx_Nimofff,"Платформа «Яндекс Учебник» заявила о расширении платформы для подготовки к ЕГЭ и добавила к информатике новый предмет — математику со встроенным помощником «Репетитором AI». Платформа содержит базу заданий Федерального института педагогических измерений, авторские пробные варианты, тематические подборки, разработанные методистами Яндекс Учебника, интерактивный тренажёр, план подготовки и Репетитора AI. Интерактивный тренажёр по математике поможет системно подготовиться к экзамену и научиться решать варианты ЕГЭ. Об этом рассказали информационной службе Хабра в пресс-службе «Яндекса».Читать далее"
https://habr.com/ru/articles/922306/,Как выбрать AI-курс для менеджера: подробный разнос,Renewal_Studio,"Обзор без маркетинга, с фокусом на то, что реально нужно менеджеру: практика, широта тем, прикладные знания, релевантность, отсутствие воды и инфоцыганщины.Как-то раз уже делался обзор по всем существующим на рынке курсам по управлению проектами, пришло время почихвостить рынок с новой, актуальной темой.  Читать далее"
https://habr.com/ru/companies/swordfish_security/articles/955464/,От экспериментов с ИИ до AI-Native: уровни зрелости и архитектура. Часть 2,YSergeev,"Всем привет! Это продолжение статьи о трансформации подхода к использованию ИИ — от базового применения к AI-Native.В первой части мы разобрали уровни зрелости искусственного интеллекта, ключевые этапы ИИ-трансформации и классификацию приложений и модальностей LLM.Читать первую частьВо второй части:Эволюция инженерных практикОт Software к Trustware: в процессе непрерывной технологической трансформацииAI-Powered Trustware Development LifecycleРиски безопасности AI-Native приложенийРешения для реализации защищенного ИИЛучшие практикиЧитать далее"
https://habr.com/ru/news/899768/,Cloud.ru разрабатывает гибридное облако с AI-инструментами,Lexx_Nimofff,"Компания Cloud.ru объявила о запуске платформы для гибридного облака с поддержкой искусственного интеллекта. Презентация прошла на конференции GoCloud. Информационная служба Хабра присутствовала на мероприятии.Новая конфигурация получила название Cloud.ru Evolution Stack AI‑bundle. Она создана на базе Cloud.ru Evolution Stack и предназначена для задач машинного обучения и AI. Платформа объединяет частное и гибридное облако с инструментами для локального запуска и разработки AI‑сервисов. Компании смогут разворачивать модели, управлять данными, масштабировать сервисы и снижать порог входа в разработку.Читать далее"
https://habr.com/ru/articles/892678/,Обзор мировых AI-платформ на конец марта 2025 (сгруппировано по странам и категориям) + ссылки на официальные сайты,trrerg,"AI-платформы и инструменты активно развиваются, предлагая решения для различных задач: от генерации текста и изображений до автономных систем и бизнес-аналитики. Локальные решения, такие как Stable Diffusion и LLaMA, позволяют использовать ИИ без подключения к интернету, что особенно важно для задач, требующих конфиденциальности и высокой производительности. Выбор платформы зависит от конкретных задач, бюджета и технических возможностей.Читать далее"
https://habr.com/ru/articles/931358/,Как трансформироваться в AI-Friendly компанию,zambas,"Введение: почему AI-трансформация — это не мода, а конкурентное преимуществоВ последние годы бизнес всё чаще сталкивается с вызовом: искусственный интеллект перестал быть “технологией будущего” — теперь это рабочий инструмент для роста, автоматизации и удержания позиций на рынке. Однако во многих компаниях AI внедряется точечно и хаотично: разные команды пилят своих агентов, чат-ботов и интеграции, зачастую не зная о работе друг друга. Результат — раздутые бюджеты, дублирование решений, высокий технический долг и замедление инноваций.Почему так происходит, к чему это приводит и как навести порядок? В этой статье — практический опыт и структурированный подход: как системно трансформировать компанию под AI, сделать бизнес AI-friendly и экономить ресурсы.Читать"
https://habr.com/ru/companies/bothub/news/883670/,"Aomni привлекает $4 миллиона, доказывая, что AI может увеличить продажи, не заменяя людей",mefdayy,"Aomni, платформа на основе AI, которая помогает отделам продаж проводить глубокое исследование потенциальных клиентов, привлекла 4 миллиона долларов в качестве начального финансирования под руководством Decibel при участии Sancus Ventures и Ride Home Fund. Компания придерживается подхода, ориентированного на человека, на рынке, перенасыщенном инструментами на основе AI, которые автоматизируют работу отделов продаж.Читать далее"
https://habr.com/ru/companies/kts/articles/814363/,"Developer Keynote Google I/O 2024: официальная поддержка KMP, развитие Gemini и AI в Андроиде",MAX1993M,"Всем привет! Меня зовут Мялкин Максим, я лид мобильной команды в KTS. Сейчас проходит Google IO 2024, и мы с ребятами в команде решили выпустить обзор треков, которые нам показались интересными. Мы сконцентрируемся на Android-направлении. На основном keynote все внимание было уделено развитию AI, также это коснулось и части разработки. В этой статье мы посмотрим что нам рассказали на developer keynote, а в следующих подробно погрузимся в технические треки.Читать далее"
https://habr.com/ru/articles/927916/,Почему промышленность — это второе лучшее применение для AI (первое — создание мемов с котами),Vlad_Karmakov,"AI — это дикий хайп. Все про него говорят. Если ты на этой неделе еще не сказал хоть что-то про нейросети, то ты, как Брежнев: медленный, смешной и ретро. Помнят тебя только бумеры, да и то не все. Но значит ли это, что AI не приносит пользу? Доказываю: приносит. Причем в таких тяжелых областях, как энергетика, производство и металлообработка.Читать далее"
